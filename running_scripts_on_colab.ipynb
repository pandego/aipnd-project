{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clone the repo, change work directory, and download the dataset"
      ],
      "metadata": {
        "id": "zakyBEw8WE3E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6X4WiMBFXgh"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/pandego/aipnd-project.git\n",
        "\n",
        "import os\n",
        "\n",
        "# Specify the path to your desired working directory\n",
        "new_directory = '/content/aipnd-project'  # Change this to your desired directory path\n",
        "\n",
        "# Change the working directory\n",
        "os.chdir(new_directory)\n",
        "\n",
        "! wget https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz\n",
        "! mkdir flowers\n",
        "! tar -xzvf \"flower_data.tar.gz\" -C \"./flowers\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_vAwLKv-EKd",
        "outputId": "a969db7b-ed73-42c3-8137-eef4ed604b17"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/aipnd-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reducing the Dataset\n",
        "In order to be able to run quick test, I am going to reduce the dataset to 3 images max per class. I will accomplish that by running the following bash script:\n",
        "\n",
        "```\n",
        "for split in train valid test; do\n",
        "    for class_dir in flowers/$split/*; do\n",
        "        [ -d \"$class_dir\" ] && (find \"$class_dir\" -type f -name \"*.jpg\" | sort | tail -n +4 | xargs rm -f)\n",
        "    done\n",
        "done\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vLe6znmVL3NU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! bash reduce_dataset.sh"
      ],
      "metadata": {
        "id": "ck5y_dqzL4hD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing out the scripts:"
      ],
      "metadata": {
        "id": "qUdz2uZGWdCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Train\n",
        "Train a new network on a data set with `train.py`\n",
        "\n",
        "- Basic usage:\n",
        "```\n",
        "python train.py data_directory\n",
        "```\n",
        "- Prints out training loss, validation loss, and validation accuracy as the network trains\n",
        "- Options:\n",
        "  - Set directory to save checkpoints:\n",
        "```\n",
        "python train.py data_dir --save_dir save_directory\n",
        "```\n",
        "  - Choose architecture:\n",
        "```\n",
        "python train.py data_dir --arch \"vgg13\"\n",
        "```\n",
        "  - Set hyperparameters:\n",
        "```\n",
        "python train.py data_dir --learning_rate 0.01 --hidden_units 512 --epochs 20\n",
        "```\n",
        "  - Use GPU for training:\n",
        "    ```\n",
        "    python train.py data_dir --gpu\n",
        "    ```"
      ],
      "metadata": {
        "id": "m2vWMwTXAThW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv6sPxno9zXj",
        "outputId": "c2210a12-437f-40a7-e70e-566f5a3481f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 177MB/s]\n",
            "Using cuda for training...\n",
            "Start training on architecture resnet18...\n",
            "Epoch 1/1.. Train loss: 4.863.. Validation loss: 4.632.. Validation accuracy: 0.003\n",
            "Epoch 1/1.. Train loss: 4.993.. Validation loss: 4.629.. Validation accuracy: 0.007\n",
            "Epoch 1/1.. Train loss: 4.785.. Validation loss: 4.620.. Validation accuracy: 0.007\n",
            "Epoch 1/1.. Train loss: 4.840.. Validation loss: 4.613.. Validation accuracy: 0.010\n",
            "Epoch 1/1.. Train loss: 4.744.. Validation loss: 4.604.. Validation accuracy: 0.013\n",
            "Epoch 1/1.. Train loss: 4.832.. Validation loss: 4.598.. Validation accuracy: 0.013\n",
            "Epoch 1/1.. Train loss: 4.689.. Validation loss: 4.587.. Validation accuracy: 0.026\n",
            "Epoch 1/1.. Train loss: 4.920.. Validation loss: 4.575.. Validation accuracy: 0.023\n",
            "Epoch 1/1.. Train loss: 4.717.. Validation loss: 4.565.. Validation accuracy: 0.036\n",
            "Epoch 1/1.. Train loss: 4.657.. Validation loss: 4.559.. Validation accuracy: 0.033\n",
            "Training finished!\n",
            "###\n",
            "Test loss: 4.567.. Test accuracy: 0.030\n",
            "###\n",
            "Saving model...\n",
            "Model saved: 'checkpoints/resnet18_checkpoint.pth'\n"
          ]
        }
      ],
      "source": [
        "! python train.py \"flowers\" --gpu --epochs 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py \"flowers\" --gpu --epochs 1 --arch \"vgg16\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "365RE1U2LagO",
        "outputId": "efd02439-b688-458e-c359-95480e3c95fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100% 528M/528M [00:02<00:00, 244MB/s]\n",
            "Using cuda for training...\n",
            "Start training on architecture vgg16...\n",
            "Epoch 1/1.. Train loss: 4.703.. Validation loss: 4.798.. Validation accuracy: 0.010\n",
            "Epoch 1/1.. Train loss: 4.875.. Validation loss: 4.856.. Validation accuracy: 0.013\n",
            "Epoch 1/1.. Train loss: 5.105.. Validation loss: 4.781.. Validation accuracy: 0.013\n",
            "Epoch 1/1.. Train loss: 4.799.. Validation loss: 4.700.. Validation accuracy: 0.013\n",
            "Epoch 1/1.. Train loss: 4.736.. Validation loss: 4.653.. Validation accuracy: 0.026\n",
            "Epoch 1/1.. Train loss: 4.695.. Validation loss: 4.611.. Validation accuracy: 0.054\n",
            "Epoch 1/1.. Train loss: 4.688.. Validation loss: 4.572.. Validation accuracy: 0.047\n",
            "Epoch 1/1.. Train loss: 4.877.. Validation loss: 4.550.. Validation accuracy: 0.050\n",
            "Epoch 1/1.. Train loss: 4.811.. Validation loss: 4.535.. Validation accuracy: 0.036\n",
            "Epoch 1/1.. Train loss: 4.455.. Validation loss: 4.529.. Validation accuracy: 0.033\n",
            "Training finished!\n",
            "###\n",
            "Test loss: 4.520.. Test accuracy: 0.026\n",
            "###\n",
            "Saving model...\n",
            "Model saved: 'checkpoints/vgg16_checkpoint.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py \"flowers\" --gpu --learning_rate 0.01 --hidden_units 512 --arch \"densenet121\" --epochs 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH_wfOl3Lad9",
        "outputId": "dcae9991-7b07-426f-da37-43427dbd7d28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100% 30.8M/30.8M [00:00<00:00, 208MB/s]\n",
            "Using cuda for training...\n",
            "Start training on architecture densenet121...\n",
            "Epoch 1/1.. Train loss: 4.934.. Validation loss: 6.019.. Validation accuracy: 0.010\n",
            "Epoch 1/1.. Train loss: 4.912.. Validation loss: 7.085.. Validation accuracy: 0.007\n",
            "Epoch 1/1.. Train loss: 4.827.. Validation loss: 7.325.. Validation accuracy: 0.007\n",
            "Epoch 1/1.. Train loss: 5.162.. Validation loss: 6.868.. Validation accuracy: 0.003\n",
            "Epoch 1/1.. Train loss: 5.290.. Validation loss: 7.137.. Validation accuracy: 0.010\n",
            "Epoch 1/1.. Train loss: 5.236.. Validation loss: 7.332.. Validation accuracy: 0.010\n",
            "Epoch 1/1.. Train loss: 5.146.. Validation loss: 6.544.. Validation accuracy: 0.010\n",
            "Epoch 1/1.. Train loss: 5.222.. Validation loss: 6.161.. Validation accuracy: 0.013\n",
            "Epoch 1/1.. Train loss: 5.165.. Validation loss: 5.887.. Validation accuracy: 0.013\n",
            "Epoch 1/1.. Train loss: 5.465.. Validation loss: 5.693.. Validation accuracy: 0.013\n",
            "Training finished!\n",
            "###\n",
            "Test loss: 5.790.. Test accuracy: 0.010\n",
            "###\n",
            "Saving model...\n",
            "Model saved: 'checkpoints/densenet121_checkpoint.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Predict\n",
        "Predict flower name from an image with `predict.py` along with the probability of that name. That is, you'll pass in a single image `/path/to/image` and return the flower name and class probability.\n",
        "\n",
        "- Basic usage:\n",
        "  ```\n",
        "  python predict.py /path/to/image checkpoint\n",
        "  ```\n",
        "- Options:\n",
        "  - Return top ***K*** most likely classes:\n",
        "  ```\n",
        "  python predict.py input checkpoint --top_k 3\n",
        "  ```\n",
        "  - Use a mapping of categories to real names:\n",
        "  ```\n",
        "  python predict.py input checkpoint --category_names cat_to_name.json\n",
        "  ```\n",
        "  - Use GPU for inference:\n",
        "  ```\n",
        "  python predict.py input checkpoint --gpu\n",
        "  ```"
      ],
      "metadata": {
        "id": "w54XhVvzA1-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python predict.py \"flowers/test/10/image_07090.jpg\" \"checkpoints/resnet18_checkpoint.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5u6yjjEALOu",
        "outputId": "dcce729f-80e4-494e-edea-f2b679c140f3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Using cpu for prediction...\n",
            "Predicted Flower Name: bee balm\n",
            "Probability: 2.26%\n",
            "Prediction plot saved to 'output/image_07090_prediction_output.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python predict.py \"flowers/test/102/image_08004.jpg\" \"checkpoints/vgg16_checkpoint.pth\" --category_names cat_to_name.json --gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IwnbRkPj-8E",
        "outputId": "0299d31f-e509-4a07-c5e7-a11756e315c2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Using cuda for prediction...\n",
            "Predicted Flower Name: corn poppy\n",
            "Probability: 8.88%\n",
            "Prediction plot saved to 'output/image_08004_prediction_output.png'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}